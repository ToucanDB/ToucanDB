name: ML Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run ML tests weekly on Sundays at 02:00 UTC
    - cron: '0 2 * * 0'

jobs:
  ml-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - python-version: "3.9"
            test-suite: "basic"
          - python-version: "3.11"
            test-suite: "comprehensive"
          - python-version: "3.12"
            test-suite: "performance"

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libopenblas-dev

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]
        # Install additional ML libraries for testing
        pip install scikit-learn transformers torch --index-url https://download.pytorch.org/whl/cpu

    - name: Run basic ML functionality tests
      if: matrix.test-suite == 'basic' || matrix.test-suite == 'comprehensive'
      run: |
        python -c "
        import asyncio
        import numpy as np
        from toucandb import ToucanDB, VectorSchema
        from toucandb.types import DistanceMetric, IndexType
        
        async def test():
            # Quick ML integration test
            db = await ToucanDB.create('./test_ml.tdb', encryption_key='test-key')
            schema = VectorSchema(name='ml_test', dimensions=384, metric=DistanceMetric.COSINE, index_type=IndexType.HNSW)
            collection = await db.create_collection(schema)
            
            # Test with realistic ML embeddings
            vectors = []
            for i in range(100):
                vector = np.random.random(384).astype(np.float32)
                vector = vector / np.linalg.norm(vector)
                vectors.append({'id': f'doc_{i}', 'vector': vector.tolist(), 'metadata': {'category': f'cat_{i%5}'}})
            
            await collection.insert_many(vectors)
            
            # Test search
            query = np.random.random(384).astype(np.float32)
            query = query / np.linalg.norm(query)
            results = await collection.search(query.tolist(), k=10)
            
            assert len(results) > 0, 'Search returned no results'
            assert all(r.score >= 0 for r in results), 'Invalid similarity scores'
            
            await db.close()
            print('✅ Basic ML functionality test passed')
        
        asyncio.run(test())
        "

    - name: Run comprehensive ML tests
      if: matrix.test-suite == 'comprehensive'
      run: |
        python -c "
        import asyncio
        import numpy as np
        from toucandb import ToucanDB, VectorSchema
        from toucandb.types import DistanceMetric, IndexType
        
        async def comprehensive_test():
            # Test multiple distance metrics
            metrics = [DistanceMetric.COSINE, DistanceMetric.EUCLIDEAN, DistanceMetric.DOT_PRODUCT]
            
            for metric in metrics:
                db = await ToucanDB.create(f'./test_{metric.value}.tdb', encryption_key='test-key')
                schema = VectorSchema(name=f'test_{metric.value}', dimensions=256, metric=metric, index_type=IndexType.FLAT)
                collection = await db.create_collection(schema)
                
                vectors = []
                for i in range(50):
                    vector = np.random.random(256).astype(np.float32)
                    if metric == DistanceMetric.COSINE:
                        vector = vector / np.linalg.norm(vector)
                    vectors.append({'id': f'vec_{i}', 'vector': vector.tolist(), 'metadata': {'idx': i}})
                
                await collection.insert_many(vectors)
                
                query = np.random.random(256).astype(np.float32)
                if metric == DistanceMetric.COSINE:
                    query = query / np.linalg.norm(query)
                
                results = await collection.search(query.tolist(), k=5)
                assert len(results) > 0, f'No results for {metric.value}'
                await db.close()
            
            print('✅ Comprehensive ML tests passed')
        
        asyncio.run(comprehensive_test())
        "

    - name: Run performance benchmarks
      if: matrix.test-suite == 'performance'
      run: |
        python -c "
        import asyncio
        import time
        import numpy as np
        from toucandb import ToucanDB, VectorSchema
        from toucandb.types import DistanceMetric, IndexType
        
        async def performance_test():
            db = await ToucanDB.create('./perf_test.tdb', encryption_key='perf-key')
            schema = VectorSchema(name='perf_vectors', dimensions=1024, metric=DistanceMetric.COSINE, index_type=IndexType.HNSW)
            collection = await db.create_collection(schema)
            
            # Large-scale test
            print('Generating 1000 high-dimensional vectors...')
            vectors = []
            for i in range(1000):
                vector = np.random.random(1024).astype(np.float32)
                vector = vector / np.linalg.norm(vector)
                vectors.append({'id': f'perf_vec_{i}', 'vector': vector.tolist(), 'metadata': {'batch': i//100}})
            
            # Benchmark insertion
            start_time = time.time()
            await collection.insert_many(vectors)
            insert_time = time.time() - start_time
            insert_rate = len(vectors) / insert_time
            
            print(f'Insert rate: {insert_rate:.0f} vectors/second')
            
            # Benchmark search
            query = np.random.random(1024).astype(np.float32)
            query = query / np.linalg.norm(query)
            
            search_times = []
            for _ in range(10):
                start_time = time.time()
                results = await collection.search(query.tolist(), k=20)
                search_times.append(time.time() - start_time)
            
            avg_search_time = np.mean(search_times) * 1000  # Convert to ms
            print(f'Average search time: {avg_search_time:.1f}ms')
            
            assert insert_rate > 50, f'Insert rate too slow: {insert_rate:.0f} vectors/sec'
            assert avg_search_time < 500, f'Search too slow: {avg_search_time:.1f}ms'
            
            await db.close()
            print('✅ Performance benchmarks passed')
        
        asyncio.run(performance_test())
        "

    - name: Test with real ML models (comprehensive only)
      if: matrix.test-suite == 'comprehensive'
      run: |
        python -c "
        try:
            from sentence_transformers import SentenceTransformer
            import asyncio
            from toucandb import ToucanDB, VectorSchema
            from toucandb.types import DistanceMetric, IndexType
            
            async def real_model_test():
                # Use a small model for testing
                model = SentenceTransformer('all-MiniLM-L6-v2')
                
                sentences = [
                    'Machine learning is transforming technology',
                    'Vector databases enable semantic search',
                    'Python is great for data science',
                    'Deep learning models create embeddings',
                    'ToucanDB provides secure vector storage'
                ]
                
                embeddings = model.encode(sentences)
                
                db = await ToucanDB.create('./real_model_test.tdb', encryption_key='model-key')
                schema = VectorSchema(
                    name='sentence_embeddings', 
                    dimensions=embeddings.shape[1], 
                    metric=DistanceMetric.COSINE, 
                    index_type=IndexType.HNSW
                )
                collection = await db.create_collection(schema)
                
                vectors = []
                for i, (sentence, embedding) in enumerate(zip(sentences, embeddings)):
                    vectors.append({
                        'id': f'sent_{i}',
                        'vector': embedding.tolist(),
                        'metadata': {'text': sentence, 'length': len(sentence)}
                    })
                
                await collection.insert_many(vectors)
                
                # Search for similar sentences
                query_embedding = model.encode(['AI and machine learning applications'])
                results = await collection.search(query_embedding[0].tolist(), k=3)
                
                assert len(results) > 0, 'No results from real model test'
                print(f'Real model test: Found {len(results)} similar sentences')
                for i, result in enumerate(results[:2]):
                    print(f'  {i+1}. {result.metadata[\"text\"]} (score: {result.score:.3f})')
                
                await db.close()
                print('✅ Real ML model test passed')
            
            asyncio.run(real_model_test())
        except ImportError:
            print('⚠️  Sentence transformers not available, skipping real model test')
        except Exception as e:
            print(f'⚠️  Real model test failed: {e}')
        "

    - name: Upload test artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ml-test-results-${{ matrix.python-version }}-${{ matrix.test-suite }}
        path: |
          *.tdb
          *.log
        retention-days: 7
